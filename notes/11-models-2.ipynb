{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 456,
     "status": "ok",
     "timestamp": 1707312228958,
     "user": {
      "displayName": "Lutz Hamel",
      "userId": "10287662568849688016"
     },
     "user_tz": 300
    },
    "id": "n8WKWoVMYqMy",
    "outputId": "184518ea-d365-482b-b65f-e1a2022654b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Enumerating objects: 7, done.\u001b[K\n",
      "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
      "remote: Compressing objects: 100% (1/1), done.\u001b[K\n",
      "remote: Total 4 (delta 3), reused 4 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
      "\u001b[KUnpacking objects: 100% (4/4), done.\n",
      "From https://github.com/lutzhamel/ds-assets\n",
      "   7a9c24a..79b1319  main       -> origin/main\n",
      "Updating 7a9c24a..79b1319\n",
      "Fast-forward\n",
      " assets/dsutils.py | 4 \u001b[32m++++\u001b[m\n",
      " 1 file changed, 4 insertions(+)\n"
     ]
    }
   ],
   "source": [
    "###### Config #####\n",
    "import sys, os, platform\n",
    "if os.path.isdir(\"ds-assets\"):\n",
    "  !cd ds-assets && git pull\n",
    "else:\n",
    "  !git clone https://github.com/lutzhamel/ds-assets.git\n",
    "colab = True if 'google.colab' in os.sys.modules else False\n",
    "system = platform.system() # \"Windows\", \"Linux\", \"Darwin\"\n",
    "home = \"ds-assets/assets/\"\n",
    "sys.path.append(home)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook level imports\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn import metrics \n",
    "from sklearn import model_selection \n",
    "import seaborn as sns; sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "j-Vbdm-RKsFE"
   },
   "outputs": [],
   "source": [
    "# format output from library calls\n",
    "import numpy as np\n",
    "np.set_printoptions(formatter={'float_kind':\"{:3.2f}\".format})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gjsCjE04YqM6"
   },
   "source": [
    "# Evaluating Models\n",
    "\n",
    "* You migh be wondering at this point why your models when left unrestricted\n",
    "(max_depth=None) always get a perfect score or something close to it.\n",
    "\n",
    "* Consider the iris data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 100.00%\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(home+\"iris.csv\")\n",
    "X  = df.drop(columns=['id','Species'])\n",
    "y = df[['Species']]\n",
    "\n",
    "acc = tree\\\n",
    "   .DecisionTreeClassifier(max_depth=None)\\\n",
    "   .fit(X, y)\\\n",
    "   .score(X, y)\n",
    "\n",
    "print(f\"accuracy = {acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Turns out that this is a well known phenomenon in machine learning\n",
    "\n",
    "* This can be characterized by **learning curves**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GpGoX5wvYqM6"
   },
   "source": [
    "## Learning Curves\n",
    "\n",
    "* Learning curves illustrate the general trends of learners. \n",
    "* The **blue line** illustrates what will happen when we **train and test** the model\n",
    "   with the **same data** (like we did above) - we call that the **training score**.\n",
    "* The **red line** illustrates what will happen if we **test** our model with **separate\n",
    "   data**, different from the training data - we call that the **testing score**.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/lutzhamel/ds-assets/main/assets/train-test-curves.png\"  height=\"300\" width=\"450\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FpfBnlIgYqM8"
   },
   "source": [
    "\n",
    "* It can be shown that any model can learn its training data perfectly - “memorize it”. \n",
    "* Any model can achieve a perfect score on the training data as long as it is allowed to be complex enough. \n",
    "* That is what the blue curve shows above. \n",
    "\n",
    "BUT\n",
    "\n",
    "* memorizing is not the same as learning inherent patterns\n",
    "* Memorization is extremely bad at predicting labels for data that it hasn't seen yet.  \n",
    "* Notice in the graph, models that have perfect training score perform poorly on the test data\n",
    "* That is what the red curve above shows\n",
    "* We say,\n",
    "\n",
    "<center>\n",
    "\n",
    "**Memorization does not generalize well!**\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Simply put:\n",
    "\n",
    "1. Undertrained models (low complexity models) make a lot of errors on test data because they have not learned any of the patterns yet.\n",
    "\n",
    "2. Overtrained models (high complexity models) make a lot of errors on test data because memorization is extremely bad at predicting labels on data they haven't been trained on.\n",
    "\n",
    "3. The best models make a trade-off between errors and recognizing important patterns. **Notice that for the best models the training score is not 100%!**\n",
    "\n",
    "\n",
    "\n",
    "**Observation**: In order to find the **best model** we have to **search the model space** to find just the right complexity level. We \n",
    "control the model space via the appropriate parameter settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JYglFKc2YqM9"
   },
   "source": [
    "## Searching the Model Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will demonstrate the model search using decision trees with both the iris and wisconsin breast cancer datasets.\n",
    "\n",
    "For each dataset we'll do the following:\n",
    "1. We'll split the data into  training and testing partitions\n",
    "2. Create trees from low complexity to high complexity\n",
    "3. Train each of these model and test it (testing score)\n",
    "4. We pick the model that has the **highest testing score**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yx-cHZu7YqM-"
   },
   "source": [
    "### The Iris Dataset\n",
    "\n",
    "* We start with the iris dataset.  \n",
    "* We would expect a lower testing accuracy from both the low-complexity and high-complexity models compared to a medium-complexity model\n",
    "* The medium-complexity model is most likely our best model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Gkq8K9pYYqM-"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(home+\"iris.csv\")\n",
    "XI  = df.drop(columns=['id','Species'])\n",
    "yI = df[['Species']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training and testing data partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# split the data - 70% training 30% testing\n",
    "(XI_train, XI_test, yI_train, yI_test) = \\\n",
    "    model_selection.train_test_split(XI, \n",
    "                                     yI, \n",
    "                                     train_size=0.7, \n",
    "                                     test_size=0.3, \n",
    "                                     random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to figure out how complex the max complexity tree is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_complexity = tree\\\n",
    "   .DecisionTreeClassifier(max_depth=None)\\\n",
    "   .fit(XI_train, yI_train)\\\n",
    "   .get_depth()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set up a search over the complexity of trees,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth=1          train score=0.67           test score=0.67\n",
      "max_depth=2          train score=0.96           test score=0.96\n",
      "max_depth=3          train score=0.98           test score=0.98\n",
      "max_depth=4          train score=1.00           test score=0.96\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,max_complexity+1):\n",
    "    # build a model with appropriate complexity\n",
    "    model = tree.DecisionTreeClassifier(max_depth=i).fit(XI_train, yI_train)\n",
    "    # training score\n",
    "    acc_train = model.score(XI_train, yI_train)\n",
    "    # testing score\n",
    "    acc_test = model.score(XI_test, yI_test)\n",
    "    # print results\n",
    "    print(f\"max_depth={i}\\\n",
    "          train score={acc_train:.2f} \\\n",
    "          test score={acc_test:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**: \n",
    "* From the list above, our best tree is a tree with **max_depth=3**. \n",
    "* It has the **highest test score**\n",
    "* Also notice that the training and testing scores behave just as predicted by the \n",
    "   learning curves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Is2IM9NYqNC"
   },
   "source": [
    "### Wisconsin Breast Cancer Dataset\n",
    "\n",
    "Let's try this again with a slightly larger datasest. This data set is available at <a href=\"https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)\">UCI</a>.\n",
    "The data set describes benign and malignent tumors based on image measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1707312231488,
     "user": {
      "displayName": "Lutz Hamel",
      "userId": "10287662568849688016"
     },
     "user_tz": 300
    },
    "id": "Y9Z8F6qrYqNC",
    "outputId": "736bed53-8989-4718-fb98-879ace7f1487"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(home+\"wdbc.csv\")\n",
    "XW  = df.drop(columns=['ID','Diagnosis'])\n",
    "yW = df[['Diagnosis']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data - 70% training 30% testing\n",
    "(XW_train, XW_test, yW_train, yW_test) = \\\n",
    "    model_selection.train_test_split(XW, \n",
    "                                     yW, \n",
    "                                     train_size=0.7, \n",
    "                                     test_size=0.3, \n",
    "                                     random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_complexity = tree\\\n",
    "   .DecisionTreeClassifier(max_depth=None)\\\n",
    "   .fit(XW_train, yW_train)\\\n",
    "   .get_depth()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Searching for the best tree for the Wisconsin data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth=1          train score=0.93           test score=0.90\n",
      "max_depth=2          train score=0.96           test score=0.91\n",
      "max_depth=3          train score=0.97           test score=0.93\n",
      "max_depth=4          train score=0.99           test score=0.95\n",
      "max_depth=5          train score=1.00           test score=0.94\n",
      "max_depth=6          train score=1.00           test score=0.92\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,max_complexity+1):\n",
    "    # build a model with appropriate complexity\n",
    "    model = tree\\\n",
    "        .DecisionTreeClassifier(max_depth=i,random_state=3)\\\n",
    "        .fit(XW_train, yW_train)\n",
    "    # training score\n",
    "    acc_train = model.score(XW_train, yW_train)\n",
    "    # testing score\n",
    "    acc_test = model.score(XW_test, yW_test)\n",
    "    # print results\n",
    "    print(f\"max_depth={i}\\\n",
    "          train score={acc_train:.2f} \\\n",
    "          test score={acc_test:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**:\n",
    "* Our best model is a tree with **max_depth=4**\n",
    "* It has the **highest test score**\n",
    "* Again, the training and testing scores behave just as predicted by the \n",
    "   learning curves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CIJS_MTJYqNJ"
   },
   "source": [
    "## Automating the Search: The Grid Search\n",
    "\n",
    "* As we saw above, the only way to find the best model for a particular dataset is to search for it by trying different parameters that control the complexity of the models.  \n",
    "* **Model complexity is often governed by more than one parameter**, therefore\n",
    "* The model search is usually referred to as the **grid search**.\n",
    "* The **sklearn GridSearchCV** function automates the model search\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gd2jmal2YqNK"
   },
   "source": [
    "### Grid Search with sklearn\n",
    "\n",
    "* Sklearn has a built-in grid search that searches the models space and \n",
    "   returns the **best model**\n",
    "* In our case the decision tree classifiers are governed by max_depth. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris Data\n",
    "Grid search for best model for iris data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up grid search\n",
    "depth_ceiling = tree\\\n",
    "    .DecisionTreeClassifier(max_depth=None)\\\n",
    "    .fit(XI_train, yI_train)\\\n",
    "    .get_depth()\n",
    "model = tree.DecisionTreeClassifier(random_state=3)\n",
    "param = {\n",
    "   'max_depth': list(range(1,depth_ceiling+1))\n",
    "   }              \n",
    "best_model = model_selection\\\n",
    "    .GridSearchCV(model, param)\\\n",
    "    .fit(XI_train,yI_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth=3 \t Testing Score=0.98\n"
     ]
    }
   ],
   "source": [
    "# compute the accuracy of optimal classifier\n",
    "acc = best_model.score(XI_test,yI_test)\n",
    "depth = best_model.best_estimator_.get_depth()\n",
    "print(f\"Depth={depth} \\t Testing Score={acc:3.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wisconsin Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search for best model for wisconsin data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up grid search\n",
    "depth_ceiling = tree\\\n",
    "    .DecisionTreeClassifier(max_depth=None)\\\n",
    "    .fit(XW_train, yW_train)\\\n",
    "    .get_depth()\n",
    "model = tree.DecisionTreeClassifier(random_state=3)\n",
    "param = {\n",
    "    'max_depth': list(range(1,depth_ceiling+1)),               \n",
    "    }\n",
    "best_model = model_selection\\\n",
    "    .GridSearchCV(model, param)\\\n",
    "    .fit(XW_train,yW_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth=5 \t Testing Score=0.94\n"
     ]
    }
   ],
   "source": [
    "# compute the accuracy of optimal classifier\n",
    "acc = best_model.score(XW_test,yW_test)\n",
    "depth = best_model.best_estimator_.get_depth()\n",
    "print(f\"Depth={depth} \\t Testing Score={acc:3.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Refit Score\n",
    "\n",
    "* Sklearn's grid search function performs its **own internal train-test split** in order to search for the best model\n",
    "* That means there is no need for us to perform a manual train-test split\n",
    "* We can simply use the whole data set in the search\n",
    "* This will make our search much simpler\n",
    "\n",
    "Question:\n",
    "\n",
    "* How do we evaluate the model if we used the whole data set for model searching?\n",
    "\n",
    "Answer:\n",
    "\n",
    "* We use the **whole data set for evaluation**\n",
    "* This is known as **refit**\n",
    "* The score we obtain is called the **refit score**\n",
    "\n",
    "Observation:\n",
    "\n",
    "* **There is no danger of overfitting because the grid search performed internal\n",
    "   train-test splits**\n",
    "* We will later develop the tools to demonstrate that the refit score is\n",
    "   statistically the same as a formal train-test evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting the model to the entire dataset\n",
    "depth_ceiling = tree.DecisionTreeClassifier(max_depth=None)\\\n",
    "   .fit(XI, yI)\\\n",
    "   .get_depth() # get the maximum depth of the tree for the dataset\n",
    "model = tree.DecisionTreeClassifier()\n",
    "param_grid = {\n",
    "    'max_depth': list(range(1,depth_ceiling+1))              \n",
    "    }\n",
    "best_model = model_selection\\\n",
    "   .GridSearchCV(model, param_grid)\\\n",
    "   .fit(XI,yI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth=4 \t Accuracy=0.99\n"
     ]
    }
   ],
   "source": [
    "# evaluate the best model\n",
    "acc = best_model.score(XI,yI)\n",
    "depth = best_model.best_estimator_.get_depth()\n",
    "print(f\"Depth={depth} \\t Accuracy={acc:3.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issues with Train and Test\n",
    "\n",
    "* Train-testing relies on randomly splitting the training data into two parts.\n",
    "\n",
    "* If this split just happens to be a 'bad' split our results might be biased.\n",
    "\n",
    "Consider the following code where we randomly split the data repeatedly and train and test on the resulting partitions.  We plot the accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(home+\"iris.csv\")\n",
    "X  = df.drop(columns=['id','Species'])\n",
    "y = df[['Species']]\n",
    "acc_list = []\n",
    "for i in range(500):\n",
    "    (X_train, X_test, y_train, y_test) = \\\n",
    "        model_selection.train_test_split(X, \n",
    "                                        y, \n",
    "                                        train_size=0.8, \n",
    "                                        test_size=0.2,\n",
    "                                        shuffle=True) \n",
    "    # we limit the complexity of the trees\n",
    "    model = tree.DecisionTreeClassifier(max_depth=3).fit(X_train,y_train)\n",
    "    acc_list.append(model.score(X_test,y_test)*100)\n",
    "\n",
    "sns.histplot(acc_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We plotted the accuracies as a histogram where can see the distibution of accuracy values.\n",
    "\n",
    "* Note the range of possible resulting accuracies. Extremely good and extremely poor performances are simply a function of the random split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In cross-validation we perform two trials (model constructions) where, in each trial, we switch the roles of our two sets (see the figure below).  In order to evaluate the model performance in cross-validation, we build and evaluate a model in each trial and then take the average performance between the two models as the performance of the cross-validation.  Notice that this will mitigate the 'bad' split issue mentioned above.\n",
    "\n",
    "**Note**: In cross-validation the testing set is called the **validation set**.\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/lutzhamel/ds-assets/main/assets/2fold-xval.png\" height=\"400\" width=\"450\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we are still only dealing with a single split that might be bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-Fold Cross-Validation\n",
    "\n",
    "Here we do the following:\n",
    "* perform the split N times,\n",
    "* then train and test on each fold,\n",
    "* take the average of the model performance over the folds in order to determine the **cross-validated model performance**\n",
    "\n",
    "Example:\n",
    "* 5-fold cross-validation - split the training data into 5 partitions (folds)\n",
    "* Use each fold as a test/validation set and the other folds as training set\n",
    "* Multiple splits - even if one is bad it will be balanced out by the others.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/lutzhamel/ds-assets/main/assets/5fold-xval.png\" height=\"400\" width=\"450\">\n",
    "\n",
    "**Note**: 5-fold cross-validation is interesting because each trial essentially has an 80-20 split: 80% of the data for training and 20% for testing.  This is one of the more common ways to split a dataset into training and testing sets.\n",
    "\n",
    "**Note**: \n",
    "* We have to train and test models five times in 5-fold cross-validation.\n",
    "* This exactly what GridSearchCV does by default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-dAakZWcYqNL"
   },
   "source": [
    "# Model Accuracy Reexamined\n",
    "\n",
    "The accuracy score for classifiers we have been looking at so far is a good first look at the \n",
    "performance of a classifier.  However, for sensitive classification tasks like biomedical applications\n",
    "we would like to understand the errors a classifier makes a little bit better.\n",
    "\n",
    "Consider a classification problem with two classes, then we can observe the following outcomes of a prediction of a classification model:\n",
    "\n",
    ">**true positive (TP)** -- predicted positive coincides with actual positive\n",
    ">\n",
    ">**true negative (TN)** -- predicted negative coincides with actual negative\n",
    ">\n",
    ">**false positive (FP)** -- predicted positive but actual negative (Type I error)\n",
    ">\n",
    ">**false negative (FN)** -- predicted negative but actual positive (Type II error)\n",
    ">\n",
    "\n",
    "**Observation**: Two types of errors possible!\n",
    "\n",
    "The distinction between these two types of errors is extremely important.  Consider a biomedical diagnostic\n",
    "decision model predicting the presence of a disease.  A false positive tends to not be problematic in this context because it will simply lead to more tests until it is discovered that the model make a false positive prediction.  The false negative prediction is much more troublesome; the patient is told to be disease free when in fact they are not.  Therefore, practitioners who build models for these kind of sensitive applications try to minimize false negative predictions of the models as much as possible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W3LEtcjRYqNL"
   },
   "source": [
    "### The Confusion Matrix\n",
    "\n",
    "An easy way to visualize the four outcomes of a binary decision model is the **confusion matrix**.\n",
    "* We can arrange the predictions in a matrix form\n",
    "* Errors will show up as values outside the major diagonal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ws6mbE8TYqNL"
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/lutzhamel/ds-assets/main/assets/confusion2.png\" height=\"200\" width=\"250\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b0g6hVA9YqNM"
   },
   "source": [
    "## The Wisconsin Breast Cancer Data Set\n",
    "\n",
    "Let's look at the performance of a tree model for the Wisconsin Breast Cancer Dataset using a confusion matrix.  We will evaluate the optimal tree model for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3372,
     "status": "ok",
     "timestamp": 1707312238084,
     "user": {
      "displayName": "Lutz Hamel",
      "userId": "10287662568849688016"
     },
     "user_tz": 300
    },
    "id": "f3a_kG21YqNM",
    "outputId": "31763900-0c34-43a5-d9af-24b9676d97cc"
   },
   "outputs": [],
   "source": [
    "# get data\n",
    "df = pd.read_csv(home+\"wdbc.csv\")\n",
    "X  = df.drop(columns=['ID','Diagnosis'])\n",
    "y = df[['Diagnosis']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_ceiling = tree.DecisionTreeClassifier().fit(X,y).get_depth()\n",
    "model = tree.DecisionTreeClassifier(random_state=1)\n",
    "param = {\n",
    "    'max_depth': list(range(1,depth_ceiling+1)),\n",
    "    'criterion': ['gini','entropy']\n",
    "    }\n",
    "best_model = model_selection\\\n",
    "    .GridSearchCV(model,param)\\\n",
    "    .fit(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.98\n"
     ]
    }
   ],
   "source": [
    "print(f\"accuracy={best_model.score(X,y):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**: Here we take advantage of the fact that GridSearchCV can search over **multiple model parameters**.  Here, this makes a difference!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>210</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>7</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     M    B\n",
       "M  210    2\n",
       "B    7  350"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# M label top-left corner\n",
    "# we want the malignent tumor prediction to be our \"positive\"\n",
    "labels = [\n",
    "   'M', # Malignant - positive\n",
    "   'B'  # Benign - negative\n",
    "   ]\n",
    "\n",
    "# create predicted values for target\n",
    "predict_y = best_model.predict(X)\n",
    "\n",
    "# build the confusion matrix\n",
    "cm = metrics.confusion_matrix(y,             # observed target values (rows)\n",
    "                              predict_y,     # predicted target values (columns)\n",
    "                              labels=labels) # labels for arranging the cm\n",
    "\n",
    "# cm is just an array of values, turn it into something readable\n",
    "cm_df = pd.DataFrame(cm, \n",
    "                     index=labels, \n",
    "                     columns=labels)\n",
    "\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZzN7cUPBgYap"
   },
   "source": [
    "We see that most of the instances lie on the major diagonal, that means the model predicted those instances correctly.  On the top line we also see that the model had **2 false negatives** (predicted malignant as benign) and on the bottom line it had **7 false positives** (predicted benign as malignant).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's interpret this matrix in more detail.  Summing accross the rows gives us the observed target values.\n",
    "\n",
    "* M: $210+2=212$\n",
    "* B: $7+350=357$\n",
    "\n",
    "Notice that this coincides precisely with the label counts in our data,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diagnosis\n",
       "B            357\n",
       "M            212\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['Diagnosis']].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an easy way to check that you set up your confusion matrix correcty!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ObcLj7XGvWGQ"
   },
   "source": [
    "## The Iris Data Set\n",
    "\n",
    "Here we are building a **three way confusion matrix** because we have three classification labels.  We apply our grid search to find the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2208,
     "status": "ok",
     "timestamp": 1707312240290,
     "user": {
      "displayName": "Lutz Hamel",
      "userId": "10287662568849688016"
     },
     "user_tz": 300
    },
    "id": "xsrwjAt-vuYh",
    "outputId": "71caefc8-7367-4a93-f06d-6f1df8cd0a2c"
   },
   "outputs": [],
   "source": [
    "# get data\n",
    "df = pd.read_csv(home+\"iris.csv\")\n",
    "X  = df.drop(columns=['id','Species'])\n",
    "y = df[['Species']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "depth_ceiling = tree.DecisionTreeClassifier().fit(X,y).get_depth()\n",
    "model = model = tree.DecisionTreeClassifier(random_state=1)\n",
    "param = {\n",
    "    'max_depth': list(range(1,depth_ceiling+1))\n",
    "    }\n",
    "best_model = model_selection\\\n",
    "    .GridSearchCV(model,param)\\\n",
    "    .fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>setosa</th>\n",
       "      <th>versicolor</th>\n",
       "      <th>virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>setosa</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>versicolor</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>virginica</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            setosa  versicolor  virginica\n",
       "setosa          50           0          0\n",
       "versicolor       0          50          0\n",
       "virginica        0           1         49"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build and print the confusion matrix\n",
    "labels = ['setosa','versicolor','virginica'] # labels in alphabetic order\n",
    "\n",
    "predict_y = best_model.predict(X)\n",
    "cm = metrics.confusion_matrix(y,         # observed\n",
    "                              predict_y, # predicted\n",
    "                              labels=labels)\n",
    "cm_df = pd.DataFrame(cm, \n",
    "                     index=labels, \n",
    "                     columns=labels)\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ocIWBmB0isbb"
   },
   "source": [
    "In a three-way confusion matrix we usually do not talk about false positives or negatives.  We just **look for misclassifications and try to characterize them**.  In our case the model makes one mistake and misclassifies a single instance of virginica as a versicolor flower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "84F_LVAOYqNM"
   },
   "source": [
    "# Reading\n",
    "\n",
    "5.3 [Hyperparameters and Model Validation](https://jakevdp.github.io/PythonDataScienceHandbook/05.03-hyperparameters-and-model-validation.html)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
